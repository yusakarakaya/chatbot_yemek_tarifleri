import streamlit as st
import os
from dotenv import load_dotenv

# Yan dosyalarÄ± doÄŸrudan import ediyoruz (KlasÃ¶rleme yok)
from gemini_model import get_gemini_response
from gpt_model import get_llama_response

from langchain_community.document_loaders.csv_loader import CSVLoader
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate

load_dotenv()

st.set_page_config(page_title="ğŸ‘¨â€ğŸ³ Åef Bot KarÅŸÄ±laÅŸtÄ±rma", layout="wide")
st.title("ğŸ‘¨â€ğŸ³ AkÄ±llÄ± Yemek AsistanÄ±")

# 1. RAG HazÄ±rlÄ±ÄŸÄ± (Yerel Embedding - Ãœcretsiz ve Sorunsuz)
@st.cache_resource
def init_rag():
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    # CSV dosyasÄ±nÄ± doÄŸrudan ana dizinden oku
    loader = CSVLoader(file_path="yemek_tarifleri_tablosu.csv", encoding="utf-8")
    docs = loader.load()
    vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings)
    return vectorstore.as_retriever(search_kwargs={"k": 3})

retriever = init_rag()

# 2. Ã–NCEDEN GÄ°RÄ°LÄ° SÄ°STEM PROMPTU (Niyet YÃ¶netimi)
system_msg = (
    "Sen uzman bir ÅŸefsin. AÅŸaÄŸÄ±daki kurallara kesinlikle uy:\n"
    "1. KullanÄ±cÄ± selam verirse neÅŸeli bir ÅŸef gibi karÅŸÄ±la.\n"
    "2. Sadece yemekler ve yemek tarifleri hakkÄ±nda konuÅŸ. AlakasÄ±z her soruyu nazikÃ§e reddet.\n"
    "3. KullanÄ±cÄ± 'sepete ekle' veya 'malzemeleri listele' derse, malzemeleri madde madde sun.\n"
    "4. VedalaÅŸÄ±rken afiyet dileyerek vedalaÅŸ.\n\n"
    "BaÄŸlam (Tarif VeritabanÄ±):\n{context}"
)

prompt_template = ChatPromptTemplate.from_messages([
    ("system", system_msg),
    ("human", "{input}")
])

# 3. ARAYÃœZ
query = st.chat_input("Hangi yemeÄŸi sormak istersiniz?")

if query:
    st.info(f"Soru: {query}")
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ¤– Google Gemini 2.5")
        with st.spinner("Gemini hazÄ±rlanÄ±yor..."):
            res_gemini = get_gemini_response(retriever, prompt_template, query)
            st.markdown(res_gemini)
            
    with col2:
        st.subheader("âš¡ Meta Llama 3.3 (Groq)")
        with st.spinner("Llama hazÄ±rlanÄ±yor..."):
            res_llama = get_llama_response(retriever, prompt_template, query)
            st.markdown(res_llama)
